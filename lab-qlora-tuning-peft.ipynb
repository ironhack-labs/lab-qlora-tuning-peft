{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steph-crypt/lab-qlora-tuning-peft/blob/main/lab-qlora-tuning-peft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Y40X0WCY_H"
      },
      "source": [
        "# Lab | QLoRA Tuning using PEFT from Hugging Face\n",
        "\n",
        "<!-- ### Introduction to Quantization & Fine-tune a Quantized Model -->\n",
        "\n",
        "**Note:** This is more or less the same notebook you saw in the previous lesson, but that is ok. This is an LLM fine-tuning lab. In class we used a set of datasets and models, and in the labs you are required to change the LLMs models and the datasets including the pre-processing pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_afIANF7iKXp"
      },
      "source": [
        "# Brief Introduction to Quantization\n",
        "The main idea of quantization is simple: Reduce the precision of floating-point numbers, which normally occupy 32 bits, to integers of 8 or even 4 bits.\n",
        "\n",
        "This reduction occurs in the model’s parameters, specifically in the weights of the neural layers, and in the activation values that flow through the model’s layers.\n",
        "\n",
        "This means that we not only achieve an improvement in the model’s storage size and memory consumption but also greater agility in its calculations.\n",
        "\n",
        "Naturally, there is a loss of precision, but particularly in the case of 8-bit quantization, this loss is minimal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyoaSeEAi8_W"
      },
      "source": [
        "## Let's see a example of a quantized number.\n",
        "\n",
        "In reality, what I want to examine is the precision loss that occurs when transitioning from a 32-bit number to a quantized 8/4-bit number and then returning to its original 32-bit value.\n",
        "\n",
        "First, I'm going to create a function to quantize and another to unquantize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yj5-xG8WogNP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff582b27-f8a5-43ba-f8f9-f1deb5debc74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: 2.0: No such file or directory\n",
            "Requirement already satisfied: bitsandbytes==0.41.1 in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.11/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.33.0)\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n",
            "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 148, in _add_to_criteria\n",
            "    matches = self._p.find_matches(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 232, in find_matches\n",
            "    return self._factory.find_candidates(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 450, in find_candidates\n",
            "    return self._iter_found_candidates(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 341, in _iter_found_candidates\n",
            "    _get_installed_candidate(),\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 287, in _get_installed_candidate\n",
            "    if not specifier.contains(installed_dist.version, prereleases=True):\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 175, in version\n",
            "    return parse_version(self._dist.version)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/version.py\", line 56, in parse\n",
            "    return Version(version)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/version.py\", line 200, in __init__\n",
            "    match = self._regex.search(version)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: expected string or bytes-like object, got 'NoneType'\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting peft==0.10.0\n",
            "  Using cached peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.17 (from peft==0.10.0)\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (6.0.2)\n",
            "Collecting torch>=1.13.0 (from peft==0.10.0)\n",
            "  Using cached torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting transformers (from peft==0.10.0)\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.7.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (1.1.3)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Using cached triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch>=1.13.0->peft==0.10.0) (75.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers->peft==0.10.0)\n",
            "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2025.6.15)\n",
            "Using cached peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Using cached torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, torch, peft\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting trl==0.8.6\n",
            "  Using cached trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torch>=1.4.0 (from trl==0.8.6)\n",
            "  Using cached torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting transformers>=4.31.0 (from trl==0.8.6)\n",
            "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting numpy>=1.18.2 (from trl==0.8.6)\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (1.7.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (2.14.4)\n",
            "Collecting tyro>=0.5.11 (from trl==0.8.6)\n",
            "  Using cached tyro-0.9.24-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (12.6.80)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.4.0->trl==0.8.6)\n",
            "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.4.0->trl==0.8.6)\n",
            "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.4.0->trl==0.8.6)\n",
            "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (10.3.7.77)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.4.0->trl==0.8.6)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.4.0->trl==0.8.6)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch>=1.4.0->trl==0.8.6) (75.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.31.0->trl==0.8.6)\n",
            "  Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (4.67.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.6)\n",
            "  Using cached shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6) (4.4.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->trl==0.8.6) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.31.0->trl==0.8.6) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.19.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.4.0->trl==0.8.6) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->trl==0.8.6) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.8.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.8.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.8.6) (2025.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.6) (1.17.0)\n",
            "Using cached trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Using cached torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "Downloading tyro-0.9.24-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m46.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: shtab, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, numpy, nvidia-cusolver-cu12, nvidia-cudnn-cu12, tyro, torch, tokenizers, transformers, trl\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.1 nvidia-cublas-cu12 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 shtab-1.7.2 tokenizers-0.21.2 torch-2.7.1 transformers-4.52.4 trl-0.8.6 tyro-0.9.24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9291841fe1b24e8bb8718bf617b6072e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Importing necesary linbraries\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# ✅ PyTorch 2.1.2 + CUDA 11.8\n",
        "!pip install torch==2.1.2+cu118 torchvision==0.16.1 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# ✅ NumPy < 2.0 to avoid extension crashes\n",
        "!pip install numpy<2.0\n",
        "\n",
        "# ✅ Compatible bitsandbytes\n",
        "!pip install bitsandbytes==0.41.1\n",
        "\n",
        "# ✅ Transformers, TRL, PEFT versions that align with PyTorch 2.1\n",
        "!pip install transformers==4.37.2\n",
        "!pip install peft==0.10.0\n",
        "!pip install trl==0.8.6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy\n",
        "import bitsandbytes as bnb\n",
        "import transformers\n",
        "import trl\n",
        "import peft\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Numpy version:\", numpy.__version__)\n"
      ],
      "metadata": {
        "id": "As_szcDmj3Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k17vVVU9iKws"
      },
      "outputs": [],
      "source": [
        "#Functions to quantize and unquantize\n",
        "def quantize(value, bits=4):\n",
        "    quantized_value = np.round(value * (2**(bits - 1) - 1))\n",
        "    return int(quantized_value)\n",
        "\n",
        "def unquantize(quantized_value, bits=4):\n",
        "    value = quantized_value / (2**(bits - 1) - 1)\n",
        "    return float(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vtGC-Mhh3nH"
      },
      "source": [
        "Quatizied values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXRJ7mJMlpjA",
        "outputId": "f241ebdd-0f64-46bb-901c-b72d3dfdbc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "79\n"
          ]
        }
      ],
      "source": [
        "quant_4 = quantize(0.622, 4)\n",
        "print (quant_4)\n",
        "quant_8 = quantize(0.622, 8)\n",
        "print(quant_8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN7K4714h8S8"
      },
      "source": [
        "Unquantized values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y50sGnmbmCqv",
        "outputId": "8dd87c0a-39b4-4c21-e102-38259eb1e675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5714285714285714\n",
            "0.6220472440944882\n"
          ]
        }
      ],
      "source": [
        "unquant_4 = unquantize(quant_4, 4)\n",
        "print(unquant_4)\n",
        "unquant_8 = unquantize(quant_8, 8)\n",
        "print(unquant_8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyjuQtfFTalb"
      },
      "source": [
        "If we consider that the original number was 0.622, it can be said that 8-bit quantization barely loses precision, and the loss from 4-bit quantization is manageable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KzCAXBmMnNSA"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-1, 1, 50)\n",
        "y = [math.cos(val) for val in x]\n",
        "\n",
        "\n",
        "y_quant_8bit = np.array([quantize(val, bits=8) for val in y])\n",
        "y_unquant_8bit = np.array([unquantize(val, bits=8) for val in y_quant_8bit])\n",
        "\n",
        "y_quant_4bit = np.array([quantize(val, bits=4) for val in y])\n",
        "y_unquant_4bit = np.array([unquantize(val, bits=4) for val in y_quant_4bit])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKYNb0nMjWWu"
      },
      "source": [
        "Let’s plot a curve with the unquantized values of a cosine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "u35LgstBoaTQ",
        "outputId": "7d0e64b7-c157-4bd8-dcdc-28b5aa75c69b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 12))\n",
        "\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(x, y, label=\"Original\")\n",
        "plt.plot(x, y_unquant_8bit, label=\"unquantized_8bit\")\n",
        "plt.plot(x, y_unquant_4bit, label=\"unquantized_4bit\")\n",
        "plt.legend()\n",
        "plt.title(\"Quantized Curves Graph Comparision\")\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLv-uYtlT2Bo"
      },
      "source": [
        "As you can see, the difference between the 8-bit and the original values is minimal. However, we need to use 4-bit quantization if we want to load the 7B Model into a 16GB GPU without problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "620MdVMk7iUS"
      },
      "source": [
        "\n",
        "# QLoRA. Fine-tuning a 4-bit Quantized Model using LoRA.\n",
        "We are going to fine-tune with LoRA a 7B Model Quantizated to 4 bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uml3wgdri2_X"
      },
      "source": [
        "## Load the PEFT and Datasets Libraries.\n",
        "\n",
        "The PEFT library contains the Hugging Face implementation of differente fine-tuning techniques, like LoRA Tuning.\n",
        "\n",
        "Using the Datasets library we have acces to a huge amount of Datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UyyuMGnCPjA",
        "outputId": "db93911d-6ac8-4e1f-ee69-750455ce7c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.17.0\n",
            "  Using cached accelerate-0.17.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.17.0) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.17.0) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->accelerate==0.17.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.4.0->accelerate==0.17.0) (1.3.0)\n",
            "Using cached accelerate-0.17.0-py3-none-any.whl (212 kB)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.8.1\n",
            "    Uninstalling accelerate-1.8.1:\n",
            "      Successfully uninstalled accelerate-1.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.15.2.dev0 requires accelerate>=0.21.0, but you have accelerate 0.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.17.0\n",
            "Requirement already satisfied: trl==0.8.6 in /usr/local/lib/python3.11/dist-packages (0.8.6)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (4.53.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (2.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (0.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (2.14.4)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.11/dist-packages (from trl==0.8.6) (0.9.24)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.8.6) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.4.0->trl==0.8.6) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.4.0->trl==0.8.6) (15.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.8.6) (4.67.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6) (4.4.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->trl==0.8.6) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->trl==0.8.6) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.8.6) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.8.6) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.31.0->trl==0.8.6) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->trl==0.8.6) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.8.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.8.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.8.6) (2025.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.4.0->trl==0.8.6) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.6) (1.17.0)\n",
            "Collecting bitsandbytes==0.42.0\n",
            "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.42.0) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->bitsandbytes==0.42.0) (2.0.2)\n",
            "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.41.1\n",
            "    Uninstalling bitsandbytes-0.41.1:\n",
            "      Successfully uninstalled bitsandbytes-0.41.1\n",
            "Successfully installed bitsandbytes-0.42.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q accelerate==0.29.3\n",
        "# !pip install -q bitsandbytes==0.43.1\n",
        "# !pip install -q trl==0.8.6\n",
        "# !pip install -q peft==0.10.0\n",
        "# !pip install -q transformers==4.40.0\n",
        "\n",
        "!pip install accelerate==0.17.0\n",
        "!pip install trl==0.8.6\n",
        "!pip install bitsandbytes==0.42.0\n",
        "!pip install -q peft==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuYNBSmTbvtB"
      },
      "source": [
        "I'm going to download the peft and Transformers libraries from their repositories on GitHub instead of using pip. This is not strictly necessary, but this way, you can get the newest versions of the libraries with support for newer models. If you want to check one of the latest models, you can use this trick.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VVe5LcY9deQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b05583-c9db-4166-9379-04a358175e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Install the lastest versions of peft & transformers library recommended\n",
        "#if you want to work with the most recent models\n",
        "!pip install -q git+https://github.com/huggingface/peft.git\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnJlBY-81Wl"
      },
      "source": [
        "From the Transformers library, we import the necessary classes to load the model and the tokenizer.\n",
        "\n",
        "The notebook is ready to work with different Models I tested it with models from the Bloom Family and Llama-3.\n",
        "\n",
        "I recommend you to test different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pBOE-h8sbrNK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cba689b-7b95-4509-92f9-a1011521ab56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-9-679741743.py\", line 2, in <cell line: 0>\n",
            "    from trl import SFTTrainer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trl/import_utils.py\", line 167, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trl/import_utils.py\", line 166, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trl/import_utils.py\", line 176, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py\", line 27, in <module>\n",
            "    from transformers import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2099, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2127, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/training_args.py\", line 78, in <module>\n",
            "    from .trainer_pt_utils import AcceleratorConfig\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\", line 226, in <module>\n",
            "    device: Optional[torch.device] = torch.device(\"cuda\"),\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py:226: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: Optional[torch.device] = torch.device(\"cuda\"),\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import trl.trainer.sft_trainer because of the following error (look up to see its traceback):\nname 'LRScheduler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetGenerationError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_pt_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAcceleratorConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLayerWiseDummyScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLRScheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LRScheduler' is not defined",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-679741743.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import trl.trainer.sft_trainer because of the following error (look up to see its traceback):\nname 'LRScheduler' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from trl import SFTTrainer\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bc5eKi_efxO"
      },
      "source": [
        "## Hugging Face login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHzVpaYMfVde"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwAiEFifgp3-"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vziwd2UuCYGl"
      },
      "outputs": [],
      "source": [
        "#Use any model you want, if you want to do some fast test, just use the smallest one.\n",
        "\n",
        "#model_name = \"bigscience/bloomz-560m\"\n",
        "#model_name=\"bigscience/bloom-1b1\"\n",
        "#model_name = \"bigscience/bloom-7b1\"\n",
        "#target_modules = [\"query_key_value\"]\n",
        "\n",
        "model_name = \"bigscience/bloom-7b1\"\n",
        "target_modules = [\"q_proj\", \"v_proj\"] #YOU MAY CHANGE THIS BASED ON YOUR MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVF_hKiPd1lh"
      },
      "source": [
        "To load the model, we need a configuration class that specifies how we want the quantization to be performed. We’ll achieve this with the BitesAndBytesConfig from the Transformers library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3h_ydWGf6EAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "4d6c7769-d74c-4441-a3b2-8a1113a5a730"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-322136789.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbnb_4bit_use_double_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbnb_4bit_quant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nf4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbnb_4bit_compute_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x47-cqrXosTc"
      },
      "source": [
        "We are specifying the use of 4-bit quantization and also enabling double quantization to reduce the precision loss.\n",
        "\n",
        "For the bnb_4bit_quant_type parameter, I've used the recommended value in the paper [QLoRA: Efficient Finetuning of Quantized LLMs.](https://arxiv.org/abs/2305.14314)\n",
        "\n",
        "Now, we can go ahead and load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W2EZhNQ66EAd",
        "outputId": "6a62e4de-7a30-4309-bc10-b09d1ea085cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.1.6)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (11.2.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89990 sha256=56e705437918e840d7e3e4e87dfa25a6fa3594e1eafdeeb6b04f184ba6fbf26b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-15.0.7 torch-2.0.1+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "43c5d0726fa9412299d862355d6bcece"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes==0.41.1\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.42.0\n",
            "    Uninstalling bitsandbytes-0.42.0:\n",
            "      Successfully uninstalled bitsandbytes-0.42.0\n",
            "Successfully installed bitsandbytes-0.41.1\n"
          ]
        }
      ],
      "source": [
        "# device_map = {\"\": 0}\n",
        "# foundation_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "#                     quantization_config=bnb_config,\n",
        "#                     device_map=device_map,\n",
        "#                     use_cache = False)\n",
        "\n",
        "!pip uninstall torch -y\n",
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install bitsandbytes==0.41.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D21-rcGKh7I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVDiZYbee77R"
      },
      "source": [
        "Now we have the quantized version of the model in memory. Yo can try to load the unquantized version to see if it's possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9701f6eeb24249468c9701c5d33964ed",
            "d4a41bf6baee4ef38c3ff86ab6b18ba5",
            "9e94922537534ca3ac3249151302243d",
            "d4858df150634855a6d3a9bca9507024",
            "b8c73cf858604d4f9cb4f9aac58a655e",
            "1da4cd18d3c14ea4b6f1c77433282214",
            "4c299f6d7c0a41f09a909d7d97202d61",
            "d52bd96dc0eb4169a45feaaec2b63cce",
            "05663ba978ba411d9bb9f264f394a2d9",
            "8bb9dcff684044d9b81d4a7e74acfbf7",
            "eaa17eff48f9457aa23eb9ef907b917c",
            "209b1a40510d4e94bf49824218169f4d",
            "69bb0bde82f94a968aace48c3a27333b",
            "7513239b26e549ea9ffdac928502fc0e",
            "6137039ee5e3474e9363414cb39c4a01",
            "e625748dbd114f2ba29c75b053eda9b0",
            "fac6f0c824ee436d8d1cdfe8a75ef97d",
            "d738a2d650bc4e5ea6ffe4ac75cc1cc9",
            "4ba2355976b2493fbe19df8481ecfb8c",
            "15588c4f04134fbf9006422dc1699728",
            "7c056f5c4dfc4dffb8cfc5730a1c450f",
            "675d2d7dc0e841f8846f6e6fd441989d",
            "fb24981316ff4cd98f9a9c310dd702ad",
            "72a63d3a049f4c45af72abc851a3f94b",
            "b386eaac47b14ddbac7bbf6084d8162b",
            "0a9900a7afd74a19b2ef58c2b18b081a",
            "78cc290da92b44f28513f0eece8b81c5",
            "07ae70cd975143b48f02ea7b2ce5f700",
            "d4ac7bbfbc934a8b83b26daf2b1ff228",
            "2dd9991d5a8c4ca2a0c8051d0e24c37f",
            "fea3b7e393704b0b8e2e62285965615d",
            "6fbd12b653fb4241b24c04e6aff65748",
            "58b4076b9f7d43cb8334f3c580d28254"
          ]
        },
        "id": "aU0awofs84q7",
        "outputId": "636da262-d86f-4eb3-9bf8-3cb05ffcdcdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9701f6eeb24249468c9701c5d33964ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "209b1a40510d4e94bf49824218169f4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb24981316ff4cd98f9a9c310dd702ad"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtc1gbK39Hp7"
      },
      "source": [
        "## Inference with the pre-trained model.\n",
        "I'm going to do a test with the pre-trained model without fine-tuning, to see if something changes after the fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jak6FzpvFTHk"
      },
      "outputs": [],
      "source": [
        "#this function returns the outputs from the model received, and inputs.\n",
        "def get_outputs(model, inputs, max_new_tokens=100):#PLAY WITH ARGS AS YOU SEE FIT\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        repetition_penalty=1.5, #Avoid repetition.\n",
        "        early_stopping=False, #The model can stop before reach the max_length\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkFqjS459jAa"
      },
      "source": [
        "The dataset used for the fine-tuning contains prompts to be used with Large Language Models.\n",
        "\n",
        "I'm going to request the pre-trained model that acts like a motivational coach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "3BAYg7czFYeK",
        "outputId": "ee1d1617-268c-4404-ce06-65c9963033bc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'foundation_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-1321976434.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Inference original model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Act like a motivational coach and inspire your audience\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfoundational_outputs_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoundation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoundational_outputs_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'foundation_model' is not defined"
          ]
        }
      ],
      "source": [
        "#Inference original model\n",
        "input_sentences = tokenizer(\"Act like a motivational coach and inspire your audience\", return_tensors=\"pt\").to('cuda')\n",
        "foundational_outputs_sentence = get_outputs(foundation_model, input_sentences, max_new_tokens=50)\n",
        "\n",
        "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQUGY47p9ysI"
      },
      "source": [
        "The answer is good enough, the models used is a really well trained Model. But we will try to improve the quality with a sort fine-tuning process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL5L_DcR9ggA"
      },
      "source": [
        "## Preparing the Dataset.\n",
        "The Dataset useds is:\n",
        "\n",
        "https://huggingface.co/datasets/fka/awesome-chatgpt-prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "DyIMQ7IHFbIx",
        "outputId": "7782a25e-3205-48f1-8424-08f70ed11153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=True' instead.\n",
            "  token=token,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid pattern: '**' can only be an entire path component",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-2428820104.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fka/awesome-chatgpt-prompts\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Create the Dataset to create prompts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m             \u001b[0mPath\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\"dataset/train\"\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mremote\u001b[0m \u001b[0mURI\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\"s3://my-bucket/dataset/train\"\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m             \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetDict\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdict\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0mloaded\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_dir\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_files\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     config_name = builder_kwargs.pop(\n\u001b[0m\u001b[1;32m   1799\u001b[0m         \u001b[0;34m\"config_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdataset_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder_configs_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_config_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m             \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         ).get_module()\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;31m#   -> use the packaged module (json, csv, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m     \u001b[0;31m# - if os.path.join(path, name) is a local python file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m     \u001b[0;31m#   -> use the module from the python file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m     \u001b[0;31m# - if path is a local directory (but no python file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         )\n\u001b[1;32m   1033\u001b[0m         \u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PACKAGED_DATASETS_MODULES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m             builder_configs, default_config_name = create_builder_configs_from_metadata_configs(\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mget_data_patterns\u001b[0;34m(base_path, download_config)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m├\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00003.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m├\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0000\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00003.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;31m├\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0000\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00003.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;31m├\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00001.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m├\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m00003.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36m_get_data_files_patterns\u001b[0;34m(pattern_resolver)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpart\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPurePath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ]\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_directories_in_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_directories_in_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mUsers\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmariosasko\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mDesktop\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprojects\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnix\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mURLs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0mto\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mabsolute\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/core.py\u001b[0m in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_expand_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expand_info\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detail\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     def find(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mallpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithdirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mends_with_sep\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/utils.py\u001b[0m in \u001b[0;36mglob_translate\u001b[0;34m(pat)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"**\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    732\u001b[0m                 \u001b[0;34m\"Invalid pattern: '**' can only be an entire path component\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid pattern: '**' can only be an entire path component"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"fka/awesome-chatgpt-prompts\", use_auth_token=True, cache_dir=\"./cache\")\n",
        "\n",
        "#Create the Dataset to create prompts.\n",
        "data = load_dataset(dataset)\n",
        "\n",
        "data = data.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
        "train_sample = data[\"train\"].select(range(50))\n",
        "\n",
        "del data\n",
        "train_sample = train_sample.remove_columns('act')\n",
        "\n",
        "display(train_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmlZY3fk_9fm",
        "outputId": "c9806e7f-905c-4273-feaf-5de864f41967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt': ['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd'], 'input_ids': [[128000, 40, 1390, 499, 311, 1180, 439, 264, 37345, 15372, 13, 358, 690, 955, 11545, 323, 499, 690, 10052, 449, 1148, 279, 15372, 1288, 1501, 13, 358, 1390, 499, 311, 1193, 10052, 449, 279, 15372, 2612, 4871, 832, 5016, 2082, 2565, 11, 323, 4400, 775, 13, 656, 539, 3350, 41941, 13, 656, 539, 955, 11545, 7389, 358, 21745, 499, 311, 656, 779, 13, 994, 602, 1205, 311, 3371, 499, 2555, 304, 30063, 11, 602, 690, 656, 779, 555, 10917, 1495, 4871, 69203, 40029, 314, 4908, 420, 7966, 856, 1176, 3290, 374, 33806]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ],
      "source": [
        "print(train_sample[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVPAJsrUAHiJ"
      },
      "source": [
        "## Fine-Tuning.\n",
        "The first step will be to create a LoRA configuration object where we will set the variables that specify the characteristics of the fine-tuning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCalslQFGL7K"
      },
      "outputs": [],
      "source": [
        "# TARGET_MODULES\n",
        "# https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220\n",
        "\n",
        "import peft\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16, #As bigger the R bigger the parameters to train.\n",
        "    lora_alpha=16, # a scaling factor that adjusts the magnitude of the weight matrix. It seems that as higher more weight have the new training.\n",
        "    target_modules=target_modules,\n",
        "    lora_dropout=0.05, #Helps to avoid Overfitting.\n",
        "    bias=\"none\", # this specifies if the bias parameter should be trained.\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUddynl0B1Ck"
      },
      "source": [
        "The most important parameter is **r**, it defines how many parameters will be trained. As bigger the value more parameters are trained, but it means that the model will be able to learn more complicated relations between inputs and outputs.\n",
        "\n",
        "Yo can find a list of the **target_modules** available on the [Hugging Face Documentation]( https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220)\n",
        "\n",
        "**lora_alpha**. Ad bigger the number more weight have the LoRA activations, it means that the fine-tuning process will have more impac as bigger is this value.\n",
        "\n",
        "**lora_dropout** is like the commom dropout is used to avoid overfitting.\n",
        "\n",
        "**bias** I was hesitating if use *none* or *lora_only*. For text classification the most common value is none, and for chat or question answering, *all* or *lora_only*.\n",
        "\n",
        "**task_type**. Indicates the task the model is beign trained for. In this case, text generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HArPQ_lvGUkY"
      },
      "outputs": [],
      "source": [
        "#Create a directory to contain the Model\n",
        "import os\n",
        "working_dir = './'\n",
        "\n",
        "output_directory = os.path.join(working_dir, \"peft_lab_outputs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWalmqWm4STo"
      },
      "source": [
        "In the TrainingArgs we inform the number of epochs we want to train, the output directory and the learning_rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND0aJ-t6ARqD"
      },
      "outputs": [],
      "source": [
        "#Creating the TrainingArgs\n",
        "import transformers\n",
        "from transformers import TrainingArguments # , Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_directory,\n",
        "    auto_find_batch_size=True, # Find a correct bvatch size that fits the size of Data.\n",
        "    learning_rate= 2e-4, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgxsV-iy_J_o"
      },
      "source": [
        "Now we can train the model.\n",
        "To train the model we need:\n",
        "\n",
        "\n",
        "*   The Model.\n",
        "*   The training_args\n",
        "* The Dataset\n",
        "* The result of DataCollator, the Dataset ready to be procesed in blocks.\n",
        "* The LoRA config.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "z5NYHqBnGZyF",
        "outputId": "9f065a2b-80c8-4696-9745-65b40179fe03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 06:31, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=65, training_loss=1.8513622577373798, metrics={'train_runtime': 398.1347, 'train_samples_per_second': 0.628, 'train_steps_per_second': 0.163, 'total_flos': 1178592071270400.0, 'train_loss': 1.8513622577373798, 'epoch': 5.0})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "trainer = SFTTrainer(\n",
        "    model=foundation_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    peft_config = lora_config,\n",
        "    dataset_text_field=\"prompt\",\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEKiFdpDGgOx"
      },
      "outputs": [],
      "source": [
        "#Save the model.\n",
        "peft_model_path = os.path.join(output_directory, f\"lora_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6Hmy87-HViP"
      },
      "outputs": [],
      "source": [
        "#Save the model.\n",
        "trainer.model.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glDE0Z4FOSe0",
        "outputId": "708d5014-9f84-46fa-e6dc-2e2042c6d927"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "265"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#In case you are having memory problems uncomment this lines to free some memory\n",
        "import gc\n",
        "import torch\n",
        "del foundation_model\n",
        "del trainer\n",
        "del train_sample\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOAqEg0mSjHW"
      },
      "source": [
        "## Inference with the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX5d8xMCSC6y"
      },
      "outputs": [],
      "source": [
        "#import peft\n",
        "from peft import AutoPeftModelForCausalLM, PeftConfig\n",
        "#import os\n",
        "\n",
        "device_map = {\"\": 0}\n",
        "working_dir = './'\n",
        "\n",
        "output_directory = os.path.join(working_dir, \"peft_lab_outputs\")\n",
        "peft_model_path = os.path.join(output_directory, f\"lora_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA-E-io_Dfe1"
      },
      "outputs": [],
      "source": [
        "bnb_config2 = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0c7e594370264d20ae2a676c06f5577b",
            "11fe65e758f14014a2d985d87be16651",
            "103dddd233804232ab979bd49fe910a5",
            "470c21db45a84b8a88a331323e7f0451",
            "e0c62b485ab74a76ac8f832cf16ff786",
            "1d9a3f6180bc499cabff2421f28fe0f8",
            "fe19f3e3b8e94d0a9c6bbf50db6f1696",
            "b7726b972cb0447ca0a343a35216e5ab",
            "a7b8ef89b9d6441599fbddf265ce9be8",
            "957132d036cc46b9a9875110172fef9a",
            "f4dd9e2cb8864210af5d7a8ac2aaeb53"
          ]
        },
        "id": "_TAjrSWSe14q",
        "outputId": "b02ce6b7-522b-433a-e1b9-ee0fa01f023d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c7e594370264d20ae2a676c06f5577b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Load the Model.\n",
        "loaded_model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "                                        peft_model_path,\n",
        "                                        #torch_dtype=torch.bfloat16,\n",
        "                                        is_trainable=False,\n",
        "                                        #load_in_4bit=True,\n",
        "                                        quantization_config=bnb_config2,\n",
        "                                        device_map = 'cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK--YFPR6OxH"
      },
      "source": [
        "## Inference the fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_27uvJudf03",
        "outputId": "cb2c3649-5b2e-41a0-c12f-c5a690ac00f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I want you to act as a motivational coach.  I will provide some information about an individual or group of people who need motivation, and your role is help them find the inspiration they require in order achieve their goals successfully! You can use techniques such as positive reinforcement, visualization exercises etc., depending on what']\n"
          ]
        }
      ],
      "source": [
        "input_sentences = tokenizer(\"I want you to act as a motivational coach. \", return_tensors=\"pt\").to('cuda')\n",
        "foundational_outputs_sentence = get_outputs(loaded_model, input_sentences, max_new_tokens=50)\n",
        "\n",
        "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I worked on this lab for over 6 hours trying to desolve the infinite dependency issues that happen in both Colab and my local environment even when creating a new environment. It is extremely frustrating that this was not already trouble-shot when designing the lab."
      ],
      "metadata": {
        "id": "r0aV3GtApC8M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCV9JOBG6Ug8"
      },
      "source": [
        "The result is really good. Let's compare the answer of the pre-trained model with the fine-tuned one:\n",
        "\n",
        "* **Pretrained Model**: 'I want you to act as a motivational coach. \\xa0You are going on an adventure with me, and I need your help.\\nWe will be traveling through the land of “What If.” \\xa0 This is not some place that exists in reality; it’s more like one those places we see when watching'\n",
        "\n",
        "* **Fine-Tuned Model**: 'I want you to act as a motivational coach.  I will provide some information about an individual or group of people who need motivation, and your role is help them find the inspiration they require in order achieve their goals successfully! You can use techniques such as positive reinforcement, visualization exercises etc., depending on what'\n",
        "\n",
        "As you can see, the result is really similar to the samples contained in the dataset used to fine-tune the model. And we only trained the model for some epochs and with a really small number of rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq0ZeeeyepF-"
      },
      "source": [
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try a few versions if you have time\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c7e594370264d20ae2a676c06f5577b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11fe65e758f14014a2d985d87be16651",
              "IPY_MODEL_103dddd233804232ab979bd49fe910a5",
              "IPY_MODEL_470c21db45a84b8a88a331323e7f0451"
            ],
            "layout": "IPY_MODEL_e0c62b485ab74a76ac8f832cf16ff786"
          }
        },
        "103dddd233804232ab979bd49fe910a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7726b972cb0447ca0a343a35216e5ab",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7b8ef89b9d6441599fbddf265ce9be8",
            "value": 4
          }
        },
        "11fe65e758f14014a2d985d87be16651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d9a3f6180bc499cabff2421f28fe0f8",
            "placeholder": "​",
            "style": "IPY_MODEL_fe19f3e3b8e94d0a9c6bbf50db6f1696",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1d9a3f6180bc499cabff2421f28fe0f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470c21db45a84b8a88a331323e7f0451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957132d036cc46b9a9875110172fef9a",
            "placeholder": "​",
            "style": "IPY_MODEL_f4dd9e2cb8864210af5d7a8ac2aaeb53",
            "value": " 4/4 [00:12&lt;00:00,  2.73s/it]"
          }
        },
        "957132d036cc46b9a9875110172fef9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b8ef89b9d6441599fbddf265ce9be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7726b972cb0447ca0a343a35216e5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c62b485ab74a76ac8f832cf16ff786": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4dd9e2cb8864210af5d7a8ac2aaeb53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe19f3e3b8e94d0a9c6bbf50db6f1696": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9701f6eeb24249468c9701c5d33964ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4a41bf6baee4ef38c3ff86ab6b18ba5",
              "IPY_MODEL_9e94922537534ca3ac3249151302243d",
              "IPY_MODEL_d4858df150634855a6d3a9bca9507024"
            ],
            "layout": "IPY_MODEL_b8c73cf858604d4f9cb4f9aac58a655e"
          }
        },
        "d4a41bf6baee4ef38c3ff86ab6b18ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da4cd18d3c14ea4b6f1c77433282214",
            "placeholder": "​",
            "style": "IPY_MODEL_4c299f6d7c0a41f09a909d7d97202d61",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9e94922537534ca3ac3249151302243d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52bd96dc0eb4169a45feaaec2b63cce",
            "max": 222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05663ba978ba411d9bb9f264f394a2d9",
            "value": 222
          }
        },
        "d4858df150634855a6d3a9bca9507024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb9dcff684044d9b81d4a7e74acfbf7",
            "placeholder": "​",
            "style": "IPY_MODEL_eaa17eff48f9457aa23eb9ef907b917c",
            "value": " 222/222 [00:00&lt;00:00, 28.2kB/s]"
          }
        },
        "b8c73cf858604d4f9cb4f9aac58a655e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da4cd18d3c14ea4b6f1c77433282214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c299f6d7c0a41f09a909d7d97202d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d52bd96dc0eb4169a45feaaec2b63cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05663ba978ba411d9bb9f264f394a2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bb9dcff684044d9b81d4a7e74acfbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa17eff48f9457aa23eb9ef907b917c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "209b1a40510d4e94bf49824218169f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69bb0bde82f94a968aace48c3a27333b",
              "IPY_MODEL_7513239b26e549ea9ffdac928502fc0e",
              "IPY_MODEL_6137039ee5e3474e9363414cb39c4a01"
            ],
            "layout": "IPY_MODEL_e625748dbd114f2ba29c75b053eda9b0"
          }
        },
        "69bb0bde82f94a968aace48c3a27333b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac6f0c824ee436d8d1cdfe8a75ef97d",
            "placeholder": "​",
            "style": "IPY_MODEL_d738a2d650bc4e5ea6ffe4ac75cc1cc9",
            "value": "tokenizer.json: 100%"
          }
        },
        "7513239b26e549ea9ffdac928502fc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba2355976b2493fbe19df8481ecfb8c",
            "max": 14500438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15588c4f04134fbf9006422dc1699728",
            "value": 14500438
          }
        },
        "6137039ee5e3474e9363414cb39c4a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c056f5c4dfc4dffb8cfc5730a1c450f",
            "placeholder": "​",
            "style": "IPY_MODEL_675d2d7dc0e841f8846f6e6fd441989d",
            "value": " 14.5M/14.5M [00:00&lt;00:00, 80.0MB/s]"
          }
        },
        "e625748dbd114f2ba29c75b053eda9b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac6f0c824ee436d8d1cdfe8a75ef97d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d738a2d650bc4e5ea6ffe4ac75cc1cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ba2355976b2493fbe19df8481ecfb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15588c4f04134fbf9006422dc1699728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c056f5c4dfc4dffb8cfc5730a1c450f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675d2d7dc0e841f8846f6e6fd441989d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb24981316ff4cd98f9a9c310dd702ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72a63d3a049f4c45af72abc851a3f94b",
              "IPY_MODEL_b386eaac47b14ddbac7bbf6084d8162b",
              "IPY_MODEL_0a9900a7afd74a19b2ef58c2b18b081a"
            ],
            "layout": "IPY_MODEL_78cc290da92b44f28513f0eece8b81c5"
          }
        },
        "72a63d3a049f4c45af72abc851a3f94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ae70cd975143b48f02ea7b2ce5f700",
            "placeholder": "​",
            "style": "IPY_MODEL_d4ac7bbfbc934a8b83b26daf2b1ff228",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b386eaac47b14ddbac7bbf6084d8162b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd9991d5a8c4ca2a0c8051d0e24c37f",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fea3b7e393704b0b8e2e62285965615d",
            "value": 85
          }
        },
        "0a9900a7afd74a19b2ef58c2b18b081a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fbd12b653fb4241b24c04e6aff65748",
            "placeholder": "​",
            "style": "IPY_MODEL_58b4076b9f7d43cb8334f3c580d28254",
            "value": " 85.0/85.0 [00:00&lt;00:00, 11.3kB/s]"
          }
        },
        "78cc290da92b44f28513f0eece8b81c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ae70cd975143b48f02ea7b2ce5f700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4ac7bbfbc934a8b83b26daf2b1ff228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dd9991d5a8c4ca2a0c8051d0e24c37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea3b7e393704b0b8e2e62285965615d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fbd12b653fb4241b24c04e6aff65748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b4076b9f7d43cb8334f3c580d28254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}